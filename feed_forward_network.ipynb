{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1.REQUIRED LIBRARY**"
      ],
      "metadata": {
        "id": "vLoTrRCagzF_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_3O0-CMWgVpd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Download dataset**"
      ],
      "metadata": {
        "id": "XKXc3VYjhsG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_mnist_datasets():\n",
        "  train_data = datasets.MNIST(\n",
        "      root = \"data\",\n",
        "      download = True,\n",
        "      train = True,\n",
        "      transform = ToTensor()\n",
        "  )\n",
        "  validation_data = datasets.MNIST(\n",
        "      root = \"data\",\n",
        "      download = True,\n",
        "      train = True,\n",
        "      transform = ToTensor()\n",
        "  )\n",
        "  return train_data,validation_data\n",
        "  #tranform is important it allow for direct transformation if required\n"
      ],
      "metadata": {
        "id": "TzZo8kGpgoy_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  #download MNIST dataset\n",
        "  train_data,_ = download_mnist_datasets()\n",
        "  print(\"MNIST dataset downloaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI6TA5DJjxEl",
        "outputId": "64b728da-9656-4f9a-b438-f2e1992641bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 241421685.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 10569382.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 85022391.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 9835069.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "MNIST dataset downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2: DATA LODER for train data**"
      ],
      "metadata": {
        "id": "4DpoykD4kzpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "train_data_loader = DataLoader(train_data,batch_size = BATCH_SIZE )"
      ],
      "metadata": {
        "id": "hUbKwqrFkQbw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.MODEL CREATION**"
      ],
      "metadata": {
        "id": "fXqrz-w0ltYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model that create will inherit from the module classes that comes directly from pytorch"
      ],
      "metadata": {
        "id": "3gEUO4MJmEdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardNet(nn.Module):\n",
        "  def __init__(self, *args, **kwargs) -> None:\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.dense_layers = nn.Sequential(\n",
        "        nn.Linear(28*28,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256,10)\n",
        "    )\n",
        "    self.softmax = nn.Softmax(dim = 1)\n",
        "  # defining the forward method\n",
        "  def forward(self,input_data):\n",
        "    flattened_data = self.flatten(input_data)\n",
        "    logits = self.dense_layers(flattened_data)\n",
        "    predictions =self.softmax(logits)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "## different layer of this model as attribute\n",
        "#initial layer will flatten the data\n",
        "#hidden layer ---> output layer\n",
        "#apply softmax\n",
        "# Sequential allow us to pack multiple layers together\n",
        "#linear is euivalend of a dense layer in keras\n",
        "# linear has two main argument input features and output features\n",
        "# images are 28x28\n",
        "# 256 neurons\n",
        "# ReLU activation function\n",
        "# 10 classes 0--->9"
      ],
      "metadata": {
        "id": "pj_N3tc-lmoN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1:**"
      ],
      "metadata": {
        "id": "1dv07IjlnMce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = \"cuba\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "print(f'using {device} device')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAGauo6Erd6c",
        "outputId": "65020470-cc69-46b4-fe2e-79a05f739062"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feed_forward_net = FeedForwardNet().to(device)"
      ],
      "metadata": {
        "id": "bk0tm2iaq2yU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Implementing Train Model**"
      ],
      "metadata": {
        "id": "Jr6k2i90tNrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model,data_loader,loss_fn,optimiser,device):\n",
        "  for inputs,targets in data_loader:\n",
        "    inputs,targets = inputs.to(device),targets.to(device)\n",
        "\n",
        "    #calculating loss\n",
        "    predictions = model(inputs)\n",
        "    loss = loss_fn(predictions,targets)\n",
        "    #backpropagation loss and update weights\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "  print(f'Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "6TJ1CceFsPgh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,data_loader,loss_fn,optimiser,device,epoch):\n",
        "  for i in range(epoch):\n",
        "    print(f'Epoch{i+1}')\n",
        "    train_one_epoch(model,data_loader,loss_fn,optimiser,device)\n",
        "    print(\".......................................\")\n",
        "  print(\"train is doen\")"
      ],
      "metadata": {
        "id": "D38LC6-yvS85"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1:train model**"
      ],
      "metadata": {
        "id": "xFyvOqlIwSJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "instantiate the loss function + optimiser"
      ],
      "metadata": {
        "id": "14ZHc1onweye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "LEARNING_RATE= 0.01\n",
        "optimiser = torch.optim.Adam(feed_forward_net.parameters(),lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "WGahnCI0wlI8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 10\n",
        "train(feed_forward_net,train_data_loader,loss_fn,optimiser,device,EPOCH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tg-zKslwKgH",
        "outputId": "6964ce9c-d38b-4431-ac0b-ca86fca6e7f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch1\n",
            "Loss: 1.5087028741836548\n",
            ".......................................\n",
            "Epoch2\n",
            "Loss: 1.5102849006652832\n",
            ".......................................\n",
            "Epoch3\n",
            "Loss: 1.4995170831680298\n",
            ".......................................\n",
            "Epoch4\n",
            "Loss: 1.4715684652328491\n",
            ".......................................\n",
            "Epoch5\n",
            "Loss: 1.4832137823104858\n",
            ".......................................\n",
            "Epoch6\n",
            "Loss: 1.471567153930664\n",
            ".......................................\n",
            "Epoch7\n",
            "Loss: 1.5022248029708862\n",
            ".......................................\n",
            "Epoch8\n",
            "Loss: 1.4817062616348267\n",
            ".......................................\n",
            "Epoch9\n",
            "Loss: 1.4719538688659668\n",
            ".......................................\n",
            "Epoch10\n",
            "Loss: 1.4928556680679321\n",
            ".......................................\n",
            "train is doen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.SAVE the model**"
      ],
      "metadata": {
        "id": "TQCWJ7JX2HuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(feed_forward_net.state_dict(),\"feedforwardnet.pth\")\n",
        "print(\"Model trainded and saved at the path\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaSp2n0yxl-7",
        "outputId": "3e870478-fd65-40ee-e232-4df6cf889556"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trainded and saved at the path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WeEBrqxs2vg1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}